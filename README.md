# Telegram-бот для отправки файлов в облачное хранилище

Сценарии использования:
1. Пользователь пишет боту /start в ответ бот присылает ему ссылку для авторизации в гугл-аккаунте (писать будем на гугл диск)
2. Пользователь авторизуется, далее присылает боту файл - бот сохраняет его в облачном хранилище, предварительно создав там папку с названием в виде текущей даты. Все файлы от текущей даты попадают в эту папку.
3. Также пользователь может получить все отправленные боту файлы за указанную дату.

Реалиализация:
1. Кластер Kubernetes с несколькими сервисами: сервис бота, брокер сообщений, сервис работы с хранилищем.   
    - Сервис бота - получает файлы от пользователя и отправляет их в брокер сообщений (аналогично в обратную сторону - получает из брокера и отправляет пользователю)
    - Сервис работы с хранилищем - получает файлы из брокера сообщений и отправляет их в хранилище (аналогично в обратную сторону - получает из хранилища отправляет в брокер).

Сервис бота запущен в одном экземпляре. Сервис работы с хранилищем в нескольких. Брокер сообщений - для повышения отказоустойчивости и горизонтального масштабирования(к одному сервису бота можно подключить несколько сервисов работы с хранилищем). 
P.S: В данном случае брокер скорее всего избыточен, так как никакого хайлоада не будет, но для потенциального масштабирования сгодится, так как вдруг в будущем захотим еще добавить какую-то обработку передаваемых файлов (ML/AI) и тогда в распараллеливании нагрузки по нескольким инстансам/подам будет действительно иметь смысл. Пока как минимум брокер можно рассматривать как шину данных между двумя сервисами. Выделение двух сервисов мне кажется логически обоснованным даже в варианте использования бота без хайлоада.

3. Снимаем метрики с обоих сервисов и отправляем их в Prometheus. Кроме метрик можно добавить сбор аналитики - в какое время чаще пользуются ботом, какие объемы загружают и т.д. В Grafana смотрим графики. 
P.S: возможно добавляем нагрузочное тестирование, чтоб понять сколько экземпляров сервисов нам надо для какой нагрузки. Исключительно в учебных целях и ради интереса.

4. Авторизация в хранилище. 
P.S: пока непонятно как делать и можно ли вообще (может API закрыто)

5. Базы и кэши. 
P.S: не придумал как их тут использовать, пока считаем что их нет - оба сервиса stateless.

6. Считаем что кластер Kubernetes запущен локально на одной машине с выходом в Интернет. 
P.S: как план максимум - разместить в облачном хостинге. 

7. Пишем на Go, как и все домашки.

Итого используемые технологии из курса: 
- kubernetes для управления docker-контейнерами и управления количеством запущенных инстансов сервиса; 
- авторизация OAuth 2.0; 
- Prometheus/Grafana для мониторинга; 
- RabbitMQ для балансировки нагрузки через очередь сообщений; 
- RabbitMQ для реализации межсервисного обмена - Event Collaboration паттерна;
- Postman для тестирования.

Установка:
- перед применением манифестов необходимо установить rabbitmq командой:    
sudo helm install mq-csysbot oci://registry-1.docker.io/bitnamicharts/rabbitmq --set auth.username='guest',auth.password='guest'
- настроить проброс портов с хоста в кластер кубернетес командой:    
sudo kubectl port-forward svc/auth-service-service 8099:8099 --address 192.168.49.1


